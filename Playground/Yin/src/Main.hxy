package;

import js.Browser;
import js.html.audio.AnalyserNode;
import js.html.audio.AudioContext;
import js.html.audio.AudioProcessingEvent;
import js.html.audio.BiquadFilterNode;
import js.html.audio.GainNode;
import js.html.audio.MediaStreamAudioSourceNode;
import js.html.Float32Array;
import js.html.RequestAnimationFrameCallback;
import js.html.rtc.LocalMediaStream;
import js.html.rtc.MediaStream;
import js.html.rtc.NavigatorUserMediaError;
import js.html.Uint32Array;
import js.html.Uint8Array;
import js.Lib;
using Lambda;

/**
 * ...
 * @author Jonas Nystr√∂m
 */

class Main 
{
	
	static function main()  new Main();
	public function new () { Browser.window.addEventListener('load', function(e) {
			
			new Pitch();
		});
	}
	
	
	
	
	
}

class Pitch {
	
	static var self:Dynamic = null;
	public function new() {
		trace('new Pitch');
		this.init();
		self = this;
		
	}
	
	/*
	function __create( stream : MediaStream ){
		trace('user media created',stream);
		// trigger unmute ?
		
		
		var __onSample = function(e : AudioProcessingEvent ){
			//var sampleData = SampleDataEvent.__create(e);
			//dispatchEvent( sampleData );
		};

	}	
	*/
	
	
	public function init( ?index = -1 ){
		
		var __onError = function(e){
			trace("error getting microphone",e);
		}

		var supported = false;
		for( k in ['getUserMedia','webkitGetUserMedia','mozGetUserMedia']){
			if( untyped js.Browser.navigator[k] != null ){
				untyped js.Browser.navigator[k]( { 
					audio : { 
						optional : [ 
							{echoCancellation : false} , 
							{echoCancelation : false} , 
							{googEchoCancellation : false} , 
							{googEchoCancellation2 : false} , 
							{googAutoGainControl : false}, 
							{googAutoGainControl2 : false}, 
							{googNoiseSuppression : false}, 
							{googNoiseSuppression2 : false}, 
							{googHighpassFilter : false}, 
							{googTypingNoiseDetection : false}, 
							{googAudioMirroring : false}
						] 
					}
				} , this.gotStream , __onError );
				supported = true;
				break;
			}
		}

		if( !supported ){
			throw "Web Audio API not supported";
		}

	}
	
	
	private function initGui() 
	{
		trace('init gui');
		    defineNoteFrequencies();
		   updatePitch();		
	}		
	
	
	function updatePitch(time=.0) 
	{
		
		
		untyped __js__('
			var pitchInHz = 0.0;
			var volumeCheck = false;
			var maxVolume = 128;
			var inputBuffer = new Uint8Array(Pitch.self.analyserNode.fftSize);
			//console.log("JS:", inputBuffer);
			
			    Pitch.self.analyserNode.getByteTimeDomainData(inputBuffer);

			    // Check for volume on the first buffer quarter
			    for (var i=0; i<inputBuffer.length/4; i++) {
			      if (maxVolume < inputBuffer[i]) maxVolume = inputBuffer[i];
			      console.log(maxVolume);
			      if (!volumeCheck && inputBuffer[i] > Pitch.self.volumeThreshold) {
			        volumeCheck = true;
			      }
			    }

			    if (volumeCheck) {
			      pitchInHz = yin_pitchEstimation(inputBuffer, Pitch.self.audioContext.sampleRate);
			    }			
			 console.log(pitchInHz);
			
			
		');
		
		
		var pitchInHz = 0.0;
		var volumeCheck = false;
		var maxVolume = 128;
		var inputBuffer:Uint8Array = new Uint8Array(this.analyserNode.fftSize);
		//untyped console.log("Haxe:", inputBuffer);
		
		/*
		this.analyserNode.getByteTimeDomainData(inputBuffer);		

		var length = Std.int(inputBuffer.length / 4);
		for (i in 0 ... length) {
			if (maxVolume < inputBuffer[i]) maxVolume = inputBuffer[i];
			if (!volumeCheck && inputBuffer[i] > this.volumeThreshold) {
				
			volumeCheck = true;
			}
		}		
		if (volumeCheck) {
			//pitchInHz = yin_pitchEstimation(inputBuffer, Std.int(audioContext.sampleRate));
			pitchInHz = untyped Yin_pitchEstimation(inputBuffer, audioContext.sampleRate);
		}
		*/
		
		
		
		/*
		
		   // Pitch smoothing logic
		    var allowedHzDifference = 5;
		    
		    if (pitchInHz != 0) {
			    
			     Browser.window.clearTimeout(silenceTimeout);			     
			      silenceTimeout = null;
			      
			      if (pitchHistory.length >= nPitchValues) pitchHistory.shift();
			      
			      // Octave jumping fix: if current pitch is around twice the previous detected pitch, halve its value
			      
			      if (pitchHistory.length != 0 && Math.abs((pitchInHz / 2.0) - pitchHistory[pitchHistory.length - 1]) < allowedHzDifference) {
				      pitchInHz = pitchInHz/2.0;
			      }
			      
			      
			      pitchInHz = Math.round(pitchInHz*10)/10;
			      pitchHistory.push(pitchInHz);
			      
			      // Take the pitch history median as the current pitch
			      var sortedPitchHistory = pitchHistory.slice(0);
			      sortedPitchHistory.sort(function(a, b) { return Std.int(a - b); } );
			      
			      pitchInHz = sortedPitchHistory[Math.floor((sortedPitchHistory.length-1)/2)];


			      updateGui(pitchInHz, getClosestNoteIndex(pitchInHz), (maxVolume-128) / 128);
			      
			      if (pitchHistory.length < nPitchValues) {
				      
					untyped __js__ ('window.requestAnimationFrame(Pitch.this.updatePitch);');
						
			      }
			      else {
				      
				        Browser.window.setTimeout(function() {
					untyped __js__ ('window.requestAnimationFrame(Pitch.this.updatePitch);');		          
				        }, minUpdateDelay);
			      }
		    } else {
			      if (this.silenceTimeout == null) {
				        this.silenceTimeout = Browser.window.setTimeout(function() {
						pitchHistory = [];
						updateGui(0.0, 0, 0);
				        }, 500);
			      }
			      untyped __js__ ('window.requestAnimationFrame(Pitch.this.updatePitch);');		          
		    }		
		    
		    */
		    Browser.window.setTimeout(function() {
			    Browser.window.requestAnimationFrame(this.updatePitch);
		    }, 1000);
		    
		    return true;
	}
	
	/*
	  function getClosestNoteIndex(f:Float):Int {
		if (f == 0.0) return 0;
		    //for (var i = 0; i < noteFrequencies.length; i++) {
		for (i in 0 ... noteFrequencies.length) {				    
			if (f < noteFrequencies[i]) {
				if (i > 0 && (noteFrequencies[i]-f > f-noteFrequencies[i-1])) return i-1;
				else return i;
			}
		}
		return 0;
	  }	
	
	
	  function updateGui(currentFreq, closestIndex, maxVolume) { trace([currentFreq, closestIndex, maxVolume]); };
	*/
	function defineNoteFrequencies() 
	{
		var noteFreq = 0.0;
		var greaterNoteFrequencies = [];
		var greaterNoteLabels = [];
		var lowerNoteFrequencies = [];
		var lowerNoteLabels = [];
		var octave = 4;

		//for (var i = 0;; i++) {
		for (i in 0 ... 10000) {
			if ((i+9)%12 == 0) octave++;
			noteFreq = refFreq*Math.pow(twelfthRootOfTwo, i);
			// maximum note tune C8 (4186.02 Hz)
			if (noteFreq > 4187) break;
			greaterNoteFrequencies.push(noteFreq);
			greaterNoteLabels.push(octave + refNoteLabels[(refNoteIndex + i) % refNoteLabels.length]);
			//trace(i);
		}
		

		octave = 4;
		//for (var i = -1;; i--) {
		for (j in 1 ... 10000) {
			var i = -j;
			if ((Math.abs(i)+2)%12 == 0) octave--;
			noteFreq = refFreq*Math.pow(twelfthRootOfTwo, i);
			// minimum note tune A0 (28Hz)
			if (noteFreq < 28) break;
			lowerNoteFrequencies.push(noteFreq);
			var relativeIndex = (refNoteIndex+i)%refNoteLabels.length;
			relativeIndex = (relativeIndex == 0) ? 0 : relativeIndex+(refNoteLabels.length);
			lowerNoteLabels.push(octave + refNoteLabels[relativeIndex]);
			//trace(j);
		}
		
		lowerNoteFrequencies.reverse();
		lowerNoteLabels.reverse();
		noteFrequencies = lowerNoteFrequencies.concat(greaterNoteFrequencies);
		noteLabels = lowerNoteLabels.concat(greaterNoteLabels);		

	}
	
	function gotStream(stream: LocalMediaStream): Bool {
		
		trace('user media created',stream);
		
		trace(this);
		
		this.audioContext = new AudioContext();
		this.microphoneNode = this.audioContext.createMediaStreamSource(stream);
		this.analyserNode = this.audioContext.createAnalyser();
		this.analyserNode.fftSize = 2048;
		this.analyserNode.smoothingTimeConstant = 0.8;
		this.gainNode = this.audioContext.createGain();
		 this.gainNode.gain.value = 1.5; // Set mic volume to 150% by default
		this.lowPassFilter1 = this.audioContext.createBiquadFilter();
		this.lowPassFilter2 = this.audioContext.createBiquadFilter();
		this.highPassFilter1 = this.audioContext.createBiquadFilter();
		this.highPassFilter2 = this.audioContext.createBiquadFilter();
		this.lowPassFilter1.Q.value = 0;
		this.lowPassFilter1.frequency.value = highestFreq;
		this.lowPassFilter1.type = BiquadFilterNode.LOWPASS;
		this.lowPassFilter2.Q.value = 0;
		this.lowPassFilter2.frequency.value = highestFreq;
		this.lowPassFilter2.type = BiquadFilterNode.LOWPASS;
		this.highPassFilter1.Q.value = 0;
		this.highPassFilter1.frequency.value = lowestFreq;
		this.highPassFilter1.type = BiquadFilterNode.HIGHPASS;
		this.highPassFilter2.Q.value = 0;
		this.highPassFilter2.frequency.value = lowestFreq;
		this.highPassFilter2.type = BiquadFilterNode.HIGHPASS;
		this.microphoneNode.connect(this.lowPassFilter1, 0, 0);
		this.lowPassFilter1.connect(this.lowPassFilter2, 0, 0);
		this.lowPassFilter2.connect(this.highPassFilter1, 0, 0);
		this.highPassFilter1.connect(this.highPassFilter2, 0, 0);
		this.highPassFilter2.connect(this.gainNode, 0, 0);
		this.gainNode.connect(this.analyserNode, 0, 0);
		
		this.initGui();
		
		return true;
		
	}


	/*
	function init() {
		trace(this);
		if (Browser.window.requestAnimationFrame == null) Lib.alert('requestAnimationFrame == null');
		this.getUserMedia = untyped __js__(' navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia; ');
		trace(this.getUserMedia);
		var getUserMedia = Browser.navigator.getUserMedia;		
		untyped __js__('getUserMedia = getUserMedia || navigator.webkitGetUserMedia;');				
		untyped __js__('getUserMedia = getUserMedia || navigator.mozGetUserMedia;');		
		untyped __js__('getUserMedia.call(navigator, { "audio": true }, this.gotStream, function() {});');		
	}
	*/
	
	
	
	
	
		
	/* Internal parameters */
	var useSPP = false; // Spectral Peak Picking (FFT + Gaussian Interpolation)
	var useAC = false; // Autocorrelation
	var useYin = true; // Yin Pitch Tracking
	var volumeThreshold = 134; // Amplitude threshold for detecting sound/silence [0-255], 128 = silence
	var nPitchValues = 5; // Number of pitches for pitch averaging logic

	/* Web Audio API variables */
	var audioContext:AudioContext = null;
	var analyserNode:AnalyserNode = null;
	var processNode = null;
	var microphoneNode:MediaStreamAudioSourceNode = null;
	var gainNode:GainNode = null;
	var lowPassFilter1:BiquadFilterNode = null;
	var lowPassFilter2:BiquadFilterNode = null;
	var highPassFilter1:BiquadFilterNode = null;
	var highPassFilter2:BiquadFilterNode = null;

	/* Configurable parameters */
	static inline var lowestFreq:Float = 30.0; // Minimum tune = 44100/1024 = 43.07Hz
	static inline var highestFreq:Float = 4200.0; // Maximum tune C8 (4186.02 Hz)

	/* Tune variables */
	var twelfthRootOfTwo = 1.05946309435929526456182529; // 2^(1/12)
	var otthRootOfTwo = 1.0005777895; // 2^(1/1200)
	var refNoteLabels = ["A", "A#", "B", "C", "C#", "D", "D#", "E", "F", "F#", "G", "G#"];
	var refFreq = 440;
	var refNoteIndex = 0;
	var noteFrequencies = [];
	var noteLabels = [];
	var pitchHistory:Array<Float> = [];

	/* GUI variables */
	var pixelsPerCent = 3;
	var silenceTimeout:Dynamic = null;
	var minUpdateDelay = 100; // Pitch/GUI maximum update rate in milliseconds	
	var getUserMedia = null;
	
	/*
	var yinThreshold = 0.15; // allowed uncertainty (e.g 0.05 will return a pitch with ~95% probability)
	var yinProbability = 0.0; // READONLY: contains the certainty of the note found as a decimal (i.e 0.3 is 30%)

	function yin_pitchEstimation(inputBuffer, sampleRate:Int) {
		
			  var yinBuffer:Float32Array = new Float32Array(Math.floor(inputBuffer.length/2));
			  yinBuffer[0] = 1;
			  var runningSum = 0;
			  var pitchInHz = 0.0;
			  var foundTau = false;
			  var minTauValue = .0;
			  var minTau = .0;

			  //for (var tau = 1; tau < Math.floor(inputBuffer.length / 2); tau++) {
			var length1 = Math.floor(inputBuffer.length / 2);
			for (tau in 1 ... length1) {
				  
			    // Step 1: Calculates the squared difference of the signal with a shifted version of itthis.
			    yinBuffer[tau] = 0;
			    
			    for (i in 0 ... length1) {
			    //for (var i=0; i<Math.floor(inputBuffer.length/2); i++) {
				var inputBufferValA = untyped __js__('inputBuffer[i]');
				var inputBufferValB = untyped __js__('inputBuffer[i+tau]');
			    
			      yinBuffer[tau] += Math.pow(((inputBufferValA-128)/128)-((inputBufferValB-128)/128),2);
			      //yinBuffer[tau] += Math.pow(((inputBuffer[i]-128)/128)-((inputBuffer[i+tau]-128)/128),2);
			    }
			    // Step 2: Calculate the cumulative mean on the normalised difference calculated in step 1.
			    runningSum += untyped __js__ (' yinBuffer[tau] ');
			    
			    yinBuffer[tau] = yinBuffer[tau]*(tau/runningSum);

			    // Step 3: Check if the current normalised cumulative mean is over the threshold.
			    if (tau > 1) {
			      if (foundTau) {
			        if (yinBuffer[tau] < minTauValue) {
			          minTauValue = yinBuffer[tau];
			          minTau = tau;
			        }
			        else break;
			      }
			      else if (yinBuffer[tau] < yinThreshold) {
			        foundTau = true;
			        minTau = tau;
			        minTauValue = yinBuffer[tau];
			      }
			    }
			  }

			  if (minTau == 0) {
			    yinProbability = 0;
			    pitchInHz = 0.0;
			  }
			  else {
			    // Step 4: Interpolate the shift value (tau) to improve the pitch estimate.
			    //minTau += (yinBuffer[minTau+1]-yinBuffer[minTau-1])/(2*((2*yinBuffer[minTau])-yinBuffer[minTau-1]-yinBuffer[minTau+1]));
			    untyped __js__ (' minTau += (yinBuffer[minTau+1]-yinBuffer[minTau-1])/(2*((2*yinBuffer[minTau])-yinBuffer[minTau-1]-yinBuffer[minTau+1])); ' );
			    
			    pitchInHz = sampleRate/minTau;
			    yinProbability = 1-minTauValue;
			  }

			  return pitchInHz;
	}	
	*/
	
}